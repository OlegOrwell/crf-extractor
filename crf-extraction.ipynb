{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  pip install sklearn-crfsuite\n",
    "#  pip install pymorphy2\n",
    "#  pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymorphy2\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yargy.tokenizer import MorphTokenizer\n",
    "from yargy import rule, Parser, or_, and_, not_\n",
    "from yargy.predicates import eq, type as type_, in_, normalized, gram, is_capitalized, dictionary\n",
    "from yargy.pipelines import morph_pipeline\n",
    "from yargy.interpretation import fact\n",
    "\n",
    "import json \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello once again! In this notebook we will extract data with Conditional Random Fields method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional random fields (CRFs) are a class of statistical modeling methods often applied in pattern recognition and machine learning and used for structured prediction. A CRF can take context into account, to do so, the predictions are modelled as a graphical model, which represents the presence of dependencies between the predictions. What kind of graph is used depends on the application. In natural language processing, \"linear chain\" CRFs are popular, for which each prediction is dependent only on its immediate neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We already know that dataset is valid and fine \n",
    "\n",
    "df = pd.read_csv(r'test_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Few words about notebook: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roadmap or what's going to happen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The task we are solving is token classification. We pick sklearn_crfsuite.CRF estimator as a tool. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is classification algorithm there are few steps to take.\n",
    "We must choose what would be our target variable and features.\n",
    "As well as decide what train, validation and test data should look like.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While working with our dataset we figured out that we have 4 classes of data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Greeting class, where managers say Hi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Introduction class, where managers introduce themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Organisation class, where managers' employer is mentioned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Farewell class, where managers say Good Bye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) All other words we are not interested in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will manually apply BIO tagging to label classes as B-GRE, I-GRE, B-NAM, I-NAM, B-ORG, I-ORG, B-FAR, I-FAR and O respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As feature samples model needs to know part of speech for every word, so I use pymorphy2 for that case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, about splitting the data. By obvious reasons we cannot add manager lines to our train set. And at the same time clients' lines dont have Organisation and Introduction classes. Also classes are highly imbalanced.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split data as all clients' lines go to train set, and all managers' go to test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give model ability to learn we will provide test set with augmented data. We will write some new lines with condition that they wouldn't duplicate test data and give some information about our classes at the same time. Which is hard especially for our Greeting and Farewell classes because of fewer possible words in these classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we can achieve good results by overfitting with augmented data, after we validate model with our manager test data, we will run additional test with some random examples too see how our model generalizes, hence how it is prone to overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start with tagging our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Retrieving indexes of manager's and client's phrases so we could differ one from another. \n",
    "\n",
    "client_index = df[df.role=='client'].index.to_list()\n",
    "manager_index = df[df.role=='manager'].index.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing with pos, and setting label O to all words \n",
    "\n",
    "tokens = [[(word, morph.parse(word)[0].tag.POS, \"O\") for i, word in enumerate(line.split())] for line in df.text.to_list()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Now pick your favourite text editor and replace O with actual tag. \n",
    "#\n",
    "#  Since we are not allowed to demostrate original test_data set.\n",
    "#  Here are first few lines \n",
    "\n",
    "sentences = [[('Алло', 'INTJ', 'O')],\n",
    " [('Алло', 'INTJ', 'O'), ('здравствуйте', 'INTJ', 'B-GRE')],\n",
    " [('Добрый', 'ADJF', 'B-GRE'), ('день', 'NOUN', 'I-GRE')],\n",
    " [('Меня', 'NPRO', 'B-NAM'),\n",
    "  ('зовут', 'VERB', 'I-NAM'),\n",
    "  ('ангелина', 'NOUN', 'I-NAM'),\n",
    "  ('компания', 'NOUN', 'B-ORG'),\n",
    "  ('диджитал', 'ADJF', 'I-ORG'),\n",
    "  ('бизнес', 'NOUN', 'I-ORG'),\n",
    "  ('звоним', 'VERB', 'O'),\n",
    "  ('вам', 'NPRO', 'O'),\n",
    "  ('по', 'PREP', 'O'),\n",
    "  ('поводу', 'NOUN', 'O'),\n",
    "  ('продления', 'NOUN', 'O'),\n",
    "  ('лицензии', 'NOUN', 'O')]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We strip lables and save them as separate file. \n",
    "#  Idea is that when notebook runs with data_test.csv \n",
    "#  it zips back words with there pos and tags from the file. \n",
    "#\n",
    "#  Hopefully original data wouldn't change and everything will work fine. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  First we want to tokenize words into nested list \n",
    "\n",
    "words = [[word for word in line.split()] for line in df.text.to_list()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Secondly we load our hand labeled markup, already saved as pos_and_tags.json\n",
    "\n",
    "with open('pos_and_tags.json', 'r') as f:\n",
    "    markup = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Let's at least check that our nested lists have same length \n",
    "\n",
    "assert len(words) == len(markup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Алло', 'INTJ', 'O')],\n",
       " [('Алло', 'INTJ', 'O'), ('здравствуйте', 'INTJ', 'B-GRE')],\n",
       " [('Добрый', 'ADJF', 'B-GRE'), ('день', 'NOUN', 'I-GRE')],\n",
       " [('Меня', 'NPRO', 'B-NAM'),\n",
       "  ('зовут', 'VERB', 'I-NAM'),\n",
       "  ('ангелина', 'NOUN', 'I-NAM'),\n",
       "  ('компания', 'NOUN', 'B-ORG'),\n",
       "  ('диджитал', 'ADJF', 'I-ORG'),\n",
       "  ('бизнес', 'NOUN', 'I-ORG'),\n",
       "  ('звоним', 'VERB', 'O'),\n",
       "  ('вам', 'NPRO', 'O'),\n",
       "  ('по', 'PREP', 'O'),\n",
       "  ('поводу', 'NOUN', 'O'),\n",
       "  ('продления', 'NOUN', 'O'),\n",
       "  ('лицензии', 'NOUN', 'O'),\n",
       "  ('а', 'CONJ', 'O'),\n",
       "  ('мы', 'NPRO', 'O'),\n",
       "  ('с', 'PREP', 'O'),\n",
       "  ('серым', 'ADJF', 'O'),\n",
       "  ('у', 'PREP', 'O'),\n",
       "  ('вас', 'NPRO', 'O'),\n",
       "  ('скоро', 'ADVB', 'O'),\n",
       "  ('срок', 'NOUN', 'O'),\n",
       "  ('заканчивается', 'VERB', 'O')]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  And zip words with markup. \n",
    "#  We should have text that looks exactly like the one few blocks higher.  \n",
    "\n",
    "sentences = [[(w, m[0], m[1]) for w, m in zip(word, mark)] for word, mark in zip(words, markup)]\n",
    "sentences[:4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate lines for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greeting class \n",
    "\n",
    "inject2 = [[('добрый', 'ADJF', 'B-GRE'), ('день', 'NOUN', 'I-GRE')], [('добрый', 'ADJF', 'B-GRE'), ('вечер', 'NOUN', 'I-GRE')],\n",
    "           [('доброе', 'ADJF', 'B-GRE'), ('утро', 'NOUN', 'I-GRE')], [('здравствуйте', 'INTJ', 'B-GRE')],           \n",
    "          ] * 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduction class \n",
    "\n",
    "inject3 = [[('Меня', 'NPRO', 'B-NAM'),\n",
    "  ('зовут', 'VERB', 'I-NAM'),\n",
    "  ('aндрей', 'NOUN', 'I-NAM')], \n",
    "  [('Меня', 'NPRO', 'B-NAM'),\n",
    "  ('сергей', 'NOUN', 'I-NAM'),\n",
    "   ('зовут', 'VERB', 'I-NAM')],        \n",
    "    [('Меня', 'NPRO', 'B-NAM'),\n",
    "  ('зовут', 'VERB', 'I-NAM'),\n",
    "  ('светлана', 'NOUN', 'I-NAM')], \n",
    "  [('Меня', 'NPRO', 'B-NAM'),\n",
    "  ('елена', 'NOUN', 'I-NAM'),\n",
    "   ('зовут', 'VERB', 'I-NAM')],              \n",
    "  [('это', 'PRCL', 'B-NAM'),\n",
    "  ('игорь', 'NOUN', 'I-NAM')],          \n",
    " [('да', 'PRCL', 'B-NAM'),\n",
    "  ('это', 'PRCL', 'I-NAM'),\n",
    "  ('александр', 'NOUN', 'I-NAM')],\n",
    " [('это', 'PRCL', 'B-NAM'),\n",
    "  ('максим', 'NOUN', 'I-NAM')]   \n",
    "] * 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organisation class\n",
    "\n",
    "inject1 = [[('компания', 'NOUN', 'B-ORG'), ('цифровой', 'ADJF', 'I-ORG'), ('бизнес', \"NOUN\", 'I-ORG')], [('компания', 'NOUN', 'B-ORG'), ('новые', 'ADJF', 'I-ORG'), ('возможности', \"NOUN\", 'I-ORG')],\n",
    "[('компания', 'NOUN', 'B-ORG'), ('новые', 'ADJF', 'I-ORG'), ('горизонты', \"NOUN\", 'I-ORG')], [('компания', 'NOUN', 'B-ORG'), ('деловые', 'ADJF', 'I-ORG'), ('линии', \"NOUN\", 'I-ORG')],          \n",
    "[('компания', 'NOUN', 'B-ORG'), ('инфобизнес', \"NOUN\", 'I-ORG')], [('компания', 'NOUN', 'B-ORG')],         \n",
    "[('компания', 'NOUN', 'B-ORG'), ('цифровой', 'ADJF', 'I-ORG'), ('бизнес', \"NOUN\", 'I-ORG')], [('компания', 'NOUN', 'B-ORG'), ('новые', 'ADJF', 'I-ORG'), ('возможноcти', \"NOUN\", 'I-ORG')],\n",
    "[('компания', 'NOUN', 'B-ORG'), ('пиксель', 'ADJF', 'I-ORG'), ('бизнес', \"NOUN\", 'I-ORG')], [('компания', 'NOUN', 'B-ORG'), ('бизнес', 'NOUN', 'I-ORG')]\n",
    "          ] * 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Farewell class\n",
    "\n",
    "inject = [[('до', 'PREP', 'B-FAR'),\n",
    "  ('свидания', 'NOUN', 'I-FAR')],\n",
    "  [('хорошего', 'ADJF', 'B-FAR'),\n",
    "  ('дня', 'NOUN', 'I-FAR')],\n",
    "[('хорошего', 'ADJF', 'B-FAR'),\n",
    "  ('вечера', 'NOUN', 'I-FAR')],\n",
    "[('доброй', 'ADJF', 'B-FAR'),\n",
    "  ('ночи', 'NOUN', 'I-FAR')],\n",
    "[('всего', 'ADJF', 'B-FAR'),\n",
    "  ('хорошего', 'ADJF', 'I-FAR')],\n",
    "[('всего', 'ADJF', 'B-FAR'),\n",
    "  ('доброго', 'ADJF', 'I-FAR')],\n",
    "[('до', 'PREP', 'B-FAR'),\n",
    "  ('новых', 'ADJF', 'I-FAR'),\n",
    " ('встреч','NOUN', 'I-FAR')]\n",
    "] * 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We increase number of samples to make classes more balanced. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we select features and procces data.\n",
    "\n",
    "Following block of code is imported from sk-learn docs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0].lower()\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [sentences[index] for index in client_index]\n",
    "test = [sentences[index] for index in manager_index]\n",
    "train = train + inject + inject1 + inject2 + inject3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train]\n",
    "y_train = [sent2labels(s) for s in train]\n",
    "\n",
    "X_test = [sent2features(s) for s in test]\n",
    "y_test = [sent2labels(s) for s in test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=9e-05, c2=5e-05, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=200,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Parameters are chosen empirically.\n",
    "#  These ones show best results for me. \n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.00009,\n",
    "    c2=0.00005,\n",
    "    max_iterations=200,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-GRE', 'I-GRE', 'B-FAR', 'I-FAR', 'B-ORG', 'I-ORG', 'B-NAM', 'I-NAM']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Remove O label \n",
    "\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9475030286714229"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And the results are: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-FAR      0.889     1.000     0.941         8\n",
      "       I-FAR      0.889     1.000     0.941         8\n",
      "       B-GRE      1.000     1.000     1.000         4\n",
      "       I-GRE      1.000     1.000     1.000         1\n",
      "       B-NAM      0.800     0.800     0.800         5\n",
      "       I-NAM      0.900     1.000     0.947         9\n",
      "       B-ORG      1.000     1.000     1.000         4\n",
      "       I-ORG      1.000     1.000     1.000         7\n",
      "\n",
      "   micro avg      0.918     0.978     0.947        46\n",
      "   macro avg      0.935     0.975     0.954        46\n",
      "weighted avg      0.920     0.978     0.948        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall error is in the line  \"Да это Анастасия\". \n",
    "\n",
    "Predicted labels are 'B-NAM', 'I-NAM', 'I-NAM' \n",
    "\n",
    "Ground truth is       'O', 'B-NAM', 'I-NAM'\n",
    "\n",
    "But anyway algorithm recognised sentence as introduction thus result suits us. \n",
      "\n",
    "Precision errors come from pos not supposed to be in the class in real life conversations, so we filter them later without loss of useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few words about metrics\n",
    "I think it's important to mention.\n",
    "While we want both precision and recall be as high as possible.\n",
    "\n",
    "In precision-recall tradeoff for this task I choose recall.\n",
    "It comes out of business logic, I can imagine here a manager control program which collects data and sends it to other managers whose job is to say how recorded behavior corresponds with company standards and more data won't hurt. \n",
    "While looking through, manager can mark unconfirmed data as false positive and we will know where model underperforms and improve it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try test model on some fresh data: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B-GRE', 'O', 'O'],\n",
       " ['B-GRE', 'I-GRE', 'O', 'O', 'O'],\n",
       " ['B-NAM', 'I-NAM', 'I-NAM', 'I-NAM'],\n",
       " ['O', 'O', 'B-FAR', 'I-FAR'],\n",
       " ['B-ORG', 'I-ORG'],\n",
       " ['B-ORG', 'I-ORG', 'O', 'O'],\n",
       " ['O', 'O', 'O', 'O', 'B-FAR', 'I-FAR']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [sent2features(s) for s in [\n",
    "        [('здравствуйте', 'INTJ', 'B-GRE'), ('заказ', 'NOUN', 'O'), ('получили', \"VERB\", 'O')], \n",
    "        [('доброе','ADJF','B-GRE'), ('утро','NOUN','I-GRE'), ('меня','ADJ','O'), ('просили','VERB','O'), ('перезвонить','VERB','O')], \n",
    "        [('меня', 'ADJF', 'B-NAM'), ('зовут', 'VERB', 'I-NAM'), ('валентина', \"NOUN\", 'I-NAM'), ('андреевна', 'NOUN', 'I-NAM')],\n",
    "        [('хорошо', 'ADJF', 'O'), ('поработали', 'VERB', 'O'), ('всего', \"ADJF\", 'B-FAR'), ('хорошего','NOUN','I-FAR')],\n",
    "        [('компания', 'NOUN', 'B-ORG'), ('сбербанк', 'NOUN', 'I-ORG')],\n",
    "        [('компания', 'NOUN', 'B-ORG'), ('самсунг', 'NOUN', 'I-ORG'), ('выиграла', 'VERB', 'O'), ('тендер', 'NOUN', 'O')],\n",
    "        [('совещание', 'NOUN', 'O'), ('перенесено', 'NOUN', 'O'), ('на', 'PREP', 'O'), \n",
    "        ('понедельник', 'NOUN', 'O'), ('до', 'PREP', 'B-FAR'), ('свидания', 'NOUN', 'I-FAR')]]]\n",
    "\n",
    "crf.predict(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm recognised all tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we shall parse the results and sort collected data by tag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "greet = rule(eq('GRE'))\n",
    "greet = Parser(greet)\n",
    "\n",
    "fare = rule(eq('FAR'))\n",
    "fare = Parser(fare)\n",
    "\n",
    "org = rule(eq('ORG'))\n",
    "org = Parser(org)\n",
    "\n",
    "intro = rule(eq('NAM'))\n",
    "intro = Parser(intro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "name = []\n",
    "list_ = []\n",
    "greet_ = []\n",
    "company = []\n",
    "farewell = []\n",
    "introduction = []\n",
    "company_label = []\n",
    "\n",
    "name_dlg = {}\n",
    "fare_dict = {}\n",
    "name_dict = {}\n",
    "greet_dict = {} \n",
    "intro_dict = {}\n",
    "company_dict = {}\n",
    "company_label_dict = {}\n",
    "\n",
    "df['name'] = False\n",
    "df['greet'] = False\n",
    "df['has_name'] = False\n",
    "df['farewell'] = False\n",
    "df['is_polite'] = False \n",
    "df['has_greet'] = False\n",
    "df['introduction'] = False\n",
    "df['has_farewell'] = False\n",
    "df['company_label'] = False\n",
    "df['has_introduction'] = False\n",
    "df['has_company_label'] = False\n",
    "\n",
    "\n",
    "#  We repeat same steps as in the Rule-Based notebook except we add few filters to the result.\n",
    "\n",
    "for sentence, index, label, dial in zip(y_pred, df[df.role=='manager'].index.to_list(), df[df.role=='manager'].text.to_list(), df[df.role=='manager'].dlg_id.to_list()):\n",
    "    for word, l in zip(sentence, label.split()):\n",
    "        greet_ = list(greet.findall(word))\n",
    "        intro_ = list(intro.findall(word))\n",
    "        company_ = list(org.findall(word))\n",
    "        farewell_ = list(fare.findall(word))\n",
    "        if greet_:\n",
    "            list_.append(greet_)\n",
    "            df['has_greet'].iloc[index] = True\n",
    "            if word[0] == \"B\": \n",
    "                greet_dict.update({index: l})\n",
    "                company.append(l)\n",
    "            else:\n",
    "                greet_dict[index] += ' '+l\n",
    "                company.extend([l])         \n",
    "        elif intro_:\n",
    "            list_.append(intro_) \n",
    "            introduction.append(l)\n",
    "            if 'Name' in morph.parse(l)[0].tag:\n",
    "                df['has_name'].iloc[index] = True\n",
    "                name_dict.update({index: l})\n",
    "                name.append(l)\n",
    "                name_dlg.update({dial: l})\n",
    "            if word[0] == \"B\": \n",
    "                intro_dict.update({index: l})\n",
    "            else:\n",
    "                intro_dict[index] += ' '+l                  \n",
    "        elif company_:\n",
    "            list_.append(company_)\n",
    "            if word[0] == \"B\": \n",
    "                company_label_dict.update({index: l})\n",
    "                company.append(l)\n",
    "            else:\n",
    "                company_label_dict[index] += ' '+l\n",
    "                company.extend([l])\n",
    "            df['has_company_label'].iloc[index] = True\n",
    "        elif farewell_:\n",
    "            list_.append(farewell_)           \n",
    "            if 'anim' not in morph.parse(label)[0].tag:\n",
    "                df['has_farewell'].iloc[index] = True\n",
    "                if word[0] == \"B\": \n",
    "                    fare_dict.update({index: l})\n",
    "                else:\n",
    "                    fare_dict[index] += ' '+l\n",
    "        else:\n",
    "            list_.append(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Let's put data from dicts to dataframe. \n",
    "\n",
    "column_name = [('greet', 'has_greet'), ('introduction', 'has_introduction'), \n",
    "               ('name', 'has_name'), ('company_label', 'has_company_label'), \n",
    "               ('farewell', 'has_farewell')]\n",
    "\n",
    "dict_list = [greet_dict, intro_dict, name_dict, company_label_dict, fare_dict]\n",
    "\n",
    "def dict2df(dictionary, name):   \n",
    "    for key, value in dictionary.items():\n",
    "        df[name[0]].iloc[key] = value\n",
    "        df[name[1]].iloc[key] = True\n",
    "\n",
    "        \n",
    "[dict2df(dictionary, name) for (dictionary, name) in zip(dict_list, column_name)]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#  And check which managers are polite. \n",
    "\n",
    "polite_dict = {}\n",
    "polite_list = []\n",
    "\n",
    "for i in df.dlg_id.unique():   \n",
    "    if (True in df[(df.dlg_id==i) & df.has_greet].has_greet.to_list()) & (True in df[(df.dlg_id==i) & df.has_farewell].has_farewell.to_list()):\n",
    "        df.is_polite[(df.dlg_id==i) & df.has_greet] = True\n",
    "        df.is_polite[(df.dlg_id==i) & df.has_farewell] = True\n",
    "        polite_dict.update({i: True})\n",
    "        polite_list.append(f'Call #{i} manager {name_dlg.get(i).capitalize()} is polite')\n",
    "    else: \n",
    "        polite_dict.update({i: False})\n",
    "        if name_dlg.get(i) == None:\n",
    "            polite_list.append(f'Call #{i} manager {name_dlg.get(i)} is NOT polite')\n",
    "        else: \n",
    "            polite_list.append(f'Call #{i} manager {name_dlg.get(i).capitalize()} is NOT polite')\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dlg_id</th>\n",
       "      <th>line_n</th>\n",
       "      <th>role</th>\n",
       "      <th>text</th>\n",
       "      <th>name</th>\n",
       "      <th>greet</th>\n",
       "      <th>has_name</th>\n",
       "      <th>farewell</th>\n",
       "      <th>is_polite</th>\n",
       "      <th>has_greet</th>\n",
       "      <th>introduction</th>\n",
       "      <th>has_farewell</th>\n",
       "      <th>company_label</th>\n",
       "      <th>has_introduction</th>\n",
       "      <th>has_company_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>manager</td>\n",
       "      <td>Алло здравствуйте</td>\n",
       "      <td>False</td>\n",
       "      <td>здравствуйте</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>manager</td>\n",
       "      <td>Всего хорошего до свидания</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>до свидания</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>manager</td>\n",
       "      <td>Алло здравствуйте</td>\n",
       "      <td>False</td>\n",
       "      <td>здравствуйте</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>manager</td>\n",
       "      <td>Угу да вижу я эту почту хорошо тогда исправлю ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>всего хорошего</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>manager</td>\n",
       "      <td>До свидания</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>До свидания</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dlg_id  line_n     role  \\\n",
       "1         0       1  manager   \n",
       "108       0     108  manager   \n",
       "110       1       1  manager   \n",
       "162       1      53  manager   \n",
       "163       1      54  manager   \n",
       "\n",
       "                                                  text   name         greet  \\\n",
       "1                                    Алло здравствуйте  False  здравствуйте   \n",
       "108                         Всего хорошего до свидания  False         False   \n",
       "110                                  Алло здравствуйте  False  здравствуйте   \n",
       "162  Угу да вижу я эту почту хорошо тогда исправлю ...  False         False   \n",
       "163                                        До свидания  False         False   \n",
       "\n",
       "     has_name        farewell  is_polite  has_greet introduction  \\\n",
       "1       False           False       True       True        False   \n",
       "108     False     до свидания       True      False        False   \n",
       "110     False           False       True       True        False   \n",
       "162     False  всего хорошего       True      False        False   \n",
       "163     False     До свидания       True      False        False   \n",
       "\n",
       "     has_farewell company_label  has_introduction  has_company_label  \n",
       "1           False         False             False              False  \n",
       "108          True         False             False              False  \n",
       "110         False         False             False              False  \n",
       "162          True         False             False              False  \n",
       "163          True         False             False              False  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  We can use df[df.is_polite] command to see greeting and farewell lines of polite managers.\n",
    "\n",
    "df[df.is_polite].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The answers are: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Извлекать реплики с приветствием – где менеджер поздоровался."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'здравствуйте',\n",
       " 110: 'здравствуйте',\n",
       " 166: 'здравствуйте',\n",
       " 250: 'добрый день'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greet_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1: 'здравствуйте',\n",
    "#  110: 'здравствуйте',\n",
    "#  166: 'здравствуйте',\n",
    "#  250: 'добрый день'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Извлекать реплики, где менеджер представил себя. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 'Меня зовут ангелина',\n",
       " 111: 'Меня зовут ангелина',\n",
       " 167: 'Меня зовут ангелина',\n",
       " 251: 'меня максим зовут',\n",
       " 338: 'Да это анастасия'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  3: 'Меня зовут ангелина',\n",
    "#  111: 'Меня зовут ангелина',\n",
    "#  167: 'Меня зовут ангелина',\n",
    "#  251: 'меня максим зовут',\n",
    "#  338: 'Да это анастасия'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Извлекать имя менеджера. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 'ангелина',\n",
       " 111: 'ангелина',\n",
       " 167: 'ангелина',\n",
       " 251: 'максим',\n",
       " 338: 'анастасия'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  3: 'ангелина',\n",
    "#  111: 'ангелина',\n",
    "#  167: 'ангелина',\n",
    "#  251: 'максим',\n",
    "#  338: 'анастасия'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Извлекать название компании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 'компания диджитал бизнес',\n",
       " 111: 'компания диджитал бизнес',\n",
       " 167: 'компания диджитал бизнес',\n",
       " 251: 'компания китобизнес'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_label_dict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  3: 'компания диджитал бизнес',\n",
    "#  111: 'компания диджитал бизнес',\n",
    "#  167: 'компания диджитал бизнес',\n",
    "#  251: 'компания китобизнес'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Извлекать реплики, где менеджер попрощался."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{108: 'до свидания',\n",
       " 162: 'всего хорошего',\n",
       " 163: 'До свидания',\n",
       " 300: 'всего доброго',\n",
       " 335: 'до свидания',\n",
       " 479: 'хорошего вечера'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fare_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  108: 'до свидания',\n",
    "#  162: 'всего хорошего',\n",
    "#  163: 'До свидания',\n",
    "#  300: 'всего доброго',\n",
    "#  335: 'до свидания',\n",
    "#  479: 'хорошего вечера'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Проверять требование к менеджеру: «В каждом диалоге обязательно необходимо поздороваться и попрощаться с клиентом»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Call #0 manager Ангелина is polite',\n",
       " 'Call #1 manager Ангелина is polite',\n",
       " 'Call #2 manager Ангелина is NOT polite',\n",
       " 'Call #3 manager Максим is polite',\n",
       " 'Call #4 manager None is NOT polite',\n",
       " 'Call #5 manager Анастасия is NOT polite']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polite_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  'Call #0 manager Ангелина is polite',\n",
    "#  'Call #1 manager Ангелина is polite',\n",
    "#  'Call #2 manager Ангелина is NOT polite',\n",
    "#  'Call #3 manager Максим is polite',\n",
    "#  'Call #4 manager None is NOT polite',\n",
    "#  'Call #5 manager Анастасия is NOT polite'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seems like we found all data we need. Hooray! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For convenience we store all data in pandas data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dlg_id</th>\n",
       "      <th>line_n</th>\n",
       "      <th>role</th>\n",
       "      <th>text</th>\n",
       "      <th>name</th>\n",
       "      <th>greet</th>\n",
       "      <th>has_name</th>\n",
       "      <th>farewell</th>\n",
       "      <th>is_polite</th>\n",
       "      <th>has_greet</th>\n",
       "      <th>introduction</th>\n",
       "      <th>has_farewell</th>\n",
       "      <th>company_label</th>\n",
       "      <th>has_introduction</th>\n",
       "      <th>has_company_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>client</td>\n",
       "      <td>Алло</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>manager</td>\n",
       "      <td>Алло здравствуйте</td>\n",
       "      <td>False</td>\n",
       "      <td>здравствуйте</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>client</td>\n",
       "      <td>Добрый день</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>manager</td>\n",
       "      <td>Меня зовут ангелина компания диджитал бизнес з...</td>\n",
       "      <td>ангелина</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Меня зовут ангелина</td>\n",
       "      <td>False</td>\n",
       "      <td>компания диджитал бизнес</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>client</td>\n",
       "      <td>Ага</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dlg_id  line_n     role                                               text  \\\n",
       "0       0       0   client                                               Алло   \n",
       "1       0       1  manager                                  Алло здравствуйте   \n",
       "2       0       2   client                                        Добрый день   \n",
       "3       0       3  manager  Меня зовут ангелина компания диджитал бизнес з...   \n",
       "4       0       4   client                                                Ага   \n",
       "\n",
       "       name         greet  has_name farewell  is_polite  has_greet  \\\n",
       "0     False         False     False    False      False      False   \n",
       "1     False  здравствуйте     False    False       True       True   \n",
       "2     False         False     False    False      False      False   \n",
       "3  ангелина         False      True    False      False      False   \n",
       "4     False         False     False    False      False      False   \n",
       "\n",
       "          introduction  has_farewell             company_label  \\\n",
       "0                False         False                     False   \n",
       "1                False         False                     False   \n",
       "2                False         False                     False   \n",
       "3  Меня зовут ангелина         False  компания диджитал бизнес   \n",
       "4                False         False                     False   \n",
       "\n",
       "   has_introduction  has_company_label  \n",
       "0             False              False  \n",
       "1             False              False  \n",
       "2             False              False  \n",
       "3              True               True  \n",
       "4             False              False  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pros, Cons and Afterthoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of CRF method is somewhat very close to Rule-Based method we used before.\n",
    "\n",
    "The difference is in Rule-Based method we explicitly set rules in which order which word to collect.\n",
    "\n",
    "While in CRF we show different examples to the model and it finds out rules itself based on probability.\n",
    "\n",
    "Maybe we could use something that would look into words' actual context?\n",
    "\n",
    "Yes we can, try my transformer model at huggingface.co \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://huggingface.co/OlegOrwell/LaBSE_ner_manager\n",
    "### Jump in! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
